{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 06: OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV is a library that contains algorithms and functions that are related to and perform image processing and computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../images/test-image.png')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', img)\n",
    "\n",
    "# press 'q' to close image or else it will not be properly closed.\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing Color Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('../images/gray.jpg', gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img', gray)\n",
    "\n",
    "# press 'q' to close image or else it will not be properly closed.\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = img.shape[:-1]\n",
    "big_image = cv2.resize(img, (2*height, 2*width))\n",
    "cv2.imshow('img', big_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_crop = img[0:500, 300:500]\n",
    "cv2.imshow('img', img_crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding only takes grayscale image.\n",
    "\n",
    "The first argument is the grayscale image, the second argument is the threshold value which is used to classify the pixel values. The third argument is the maximum value which is assigned to pixel values exceeding the threshold. OpenCV provides different types of thresholding which is given by the fourth parameter of the function.\n",
    "\n",
    "The method returns two outputs. The first is the threshold that was used and the second output is the thresholded image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow('img', thresholded[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "kernel = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "# here second argument means the depth of the output image. \n",
    "# If you set this argument to -1 then the output image will have the same depth as input image.\n",
    "filtered = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "cv2.imshow('img', filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes img, kernel size, standard deviation. If std is 0 then it is calculated from kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "cv2.imshow('img', gaussian)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First argument is grayscale image, then lower threshold, upper threshold and then kernel size which is by default 3.\n",
    "\n",
    "The edge pixels above the upper threshold are considered in an edge map and edge pixels below the threshold are discarded. The pixel in between the thresholds are considered only if they are connected to pixels in upper threshold. Thus we get a clean edge map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, 100, 200, 3)\n",
    "\n",
    "cv2.imshow('img', edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift_img = cv2.imread('../images/test-image.png')\n",
    "\n",
    "sift_obj = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# you can also pass a mask in place of None if you want to find features in a specific region.\n",
    "keypoints = sift_obj.detect(gray, None)\n",
    "\n",
    "drawn = cv2.drawKeypoints(gray, keypoints, sift_img)\n",
    "\n",
    "cv2.imshow('img', sift_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rot = cv2.imread('../images/test-image-rot.png')\n",
    "gray_rot = cv2.cvtColor(img_rot, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "# detectAndCompute will find keypoints as well as compute the descriptors\n",
    "# descriptors store information about keypoints that make them distinguishable\n",
    "kp, desc = sift.detectAndCompute(gray, None)\n",
    "kp_rot, desc_rot = sift.detectAndCompute(gray_rot, None)\n",
    "\n",
    "# this is will match the descriptors and find the ones that are similar\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(desc, desc_rot, k=2)\n",
    "\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    # applying the ratio test to filter out the bad matches due to noise\n",
    "    # since we set k=2 in bf.knnMatch() we have two matches for each keypoint\n",
    "    # the first one is the best and the second one of the second best\n",
    "    # we are decreasing the value of the worst match and checking whether its\n",
    "    # value becomes smaller then the best match. If it does then that match is discarded\n",
    "    if m.distance < 0.4 * n.distance:\n",
    "        good.append([m])\n",
    "\n",
    "random.shuffle(good)\n",
    "image_match = cv2.drawMatchesKnn(img, kp, img_rot, kp_rot, good[:10], flags=2, outImg=None)\n",
    "\n",
    "cv2.imshow('img', image_match)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while (cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while (cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('gray', gray)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "ret, frame = cam.read()\n",
    "\n",
    "h, w = frame.shape[:2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "# 1st argument: where to save video, 2nd compression format, 3rd fps, 4th size of video\n",
    "video_writer = cv2.VideoWriter('../images/gray_vid.mp4', fourcc, 25.0, (w, h))\n",
    "\n",
    "while (cam.isOpened()):\n",
    "    ret, frame = cam.read()\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     gray = cv2.Canny(gray, 30, 35, 3)\n",
    "    \n",
    "    # have to convert back to BGR format because video needs 3 channels\n",
    "    # this will not bring back the colors\n",
    "    \n",
    "    gray = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    video_writer.write(gray)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('gray', gray)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- https://docs.opencv.org/master/index.html\n",
    "- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html\n",
    "- https://www.youtube.com/playlist?list=PLQVvvaa0QuDdttJXlLtAJxJetJcqmqlQq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
